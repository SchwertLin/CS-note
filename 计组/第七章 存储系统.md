# 存储系统

[TOC]



## 概述



### 错题

1. 主存中的数据组织

![](https://s3.bmp.ovh/imgs/2022/04/10/78347a4a9690423f.png)

![](https://s3.bmp.ovh/imgs/2022/04/10/7872f397edc8ac7e.png)

![](https://s3.bmp.ovh/imgs/2022/04/10/43a7362c5b33d46e.png)

![](https://s3.bmp.ovh/imgs/2022/04/10/e246a6e78a679d04.png)

存放是： 12  34  56  78，中间只可能是  34   56

大端存储：最高字节地址是数据地址。

小端存储：最低字节地址是数据地址。

![](https://s3.bmp.ovh/imgs/2022/04/10/f69880f3004523dc.png)







## 内部存储器（主存储器）

### 静态存储器—SRAM

​	无论是读/写，都要求X和Y译码线同时有效，使得 T5 T6 T7 T8 导通。

![](https://s3.bmp.ovh/imgs/2022/04/10/e326ee4b771eb8d0.png)

![](https://s3.bmp.ovh/imgs/2022/04/10/6de5d4c21248fc96.png)

==SRAM存储单元不足：晶体管过多、存储密度低、功耗大。==



### 动态存储器—DRAM

为了解决SRAM存在的问题应运而生。

![](https://s3.bmp.ovh/imgs/2022/04/10/a0d6fb1242d25d3c.png)

==刷新操作是动态存储器所特有的操作==。由于C1，C2会漏电（在2-8ms之内漏完），所以必须存在刷新操作。刷新地址（行数）由刷新地址计数器给出。

> 为什么不是由CPU决定刷新地址？
>
> ---存储器的地址是根据指令给出，是离散的，不可能遍历所有的存储单元；但是刷新地址的得出一定要遍历所有的存储单元。

==双译码结构的DRAM刷新按行进行，需要知道DRAM芯片存储矩阵的行数==。



#### 刷新方式

**1.集中刷新**
集中刷新是在规定的一个刷新周期内，对全部存储单元集中一段时间逐行进行刷新，此刻必须停止读/写操作。

用0.5μs*128=64μs的时间对128行进行逐行刷新，由于这64μs的时间不能进行读/写操作，故称为“死时间”或访存“死区”。

由于存取周期为0.5μs，刷新周期为2ms，即4000个存取周期。

补充一点：为什么刷新与存取不能并行？
因为内存就一套地址译码和片选装置，刷新与存取有相似的过程，它要选中一行——这期间片选线、地址线、地址译码器全被占用着。同理，刷新操作之间也不能并行——意味着一次只能刷一行。

**2.分散刷新**
分散刷新是指对每行存储单元的刷新分散到每个存取周期内完成。其中，把机器的存取周期tc分成两段，前半段tM用来读/写或维持信息，后半段tR用来刷新。

即在每个存取操作后绑定一个刷新操作。延长了存取周期，这样存取周期就成了0.5μs + 0.5μs =1μs。但是由于与存取操作绑定，就不需要专门给出一段时间来刷新了。这样，每有128个读取操作，就会把0-127行全部刷新一遍。故每隔128μs 就可将存储芯片全部刷新一遍，即刷新周期是1μs×128=128μs远短于2ms，而且不存在停止读/写的死时间，但是存取周期长了，整个系统速度降低了。（分散刷新的刷新周期128μs ，其实不需要这么频繁，会导致浪费）

**3.异步刷新**
既可以缩短“死时间”，又充分利用最大刷新间隔为2ms的特点，具体操作为：在2ms内对128行各刷新一遍

即每隔15.6μs刷新一行(2000μs/128≈15.6μs)，而每行刷新的时间仍为0.5μs。这样，刷新一行只能停止一个存取周期，但对每行来说，刷新间隔时间仍为2ms，而死时间为0.5μs。（相对每一段来说，是集中式刷新，相对整体来说，是分散式刷新）

如果将DRAM的刷新安排在CPU对指令的译码阶段，由于这个阶段CPU不访问存储器，所以这种方案既克服了分散刷新需独占0.5μs用于刷新，使存取周期加长且降低系统速度的缺点，又不会出现集中刷新的访存“死区”问题，从根本上上提高了整机的工作效率。

 







### 习题

![](https://s3.bmp.ovh/imgs/2022/04/10/17c9c6cb58e13ce1.png)



![](https://s3.bmp.ovh/imgs/2022/04/10/3c63cfb5994264fb.png)

![](https://s3.bmp.ovh/imgs/2022/04/10/a1c0c1cdbedf8ac7.png)

![](https://s3.bmp.ovh/imgs/2022/04/10/14a216832ba9f558.png)

==【为什么要选D】==

--------------------------------------------DRAM&SRAM结合

![](https://s3.bmp.ovh/imgs/2022/04/12/fb461a05f9a38d46.png)

> DRAM由于在存储信息时采取了电容存储电荷，所有读操作的时候会通电，也相当于一次刷新？这样。地址引脚为12根，DRAM采用地址复用，所以容量是$2^{12*2}$

![](https://s3.bmp.ovh/imgs/2022/04/12/9697498a9962c929.png)

> 对于容量是$2^{16}$,然后DRAM采用地址复用，所以地址线减半，一共是8+8=16，C√。



### 存储扩展

常见的扩展有三种类型：位扩展、字扩展、字位扩展。

==无论哪种类型的存储扩展，都要完成CPU与主存间地址线、数据线、控制线的连接。==

**位扩展**：16k*8→16k\*32

**字扩展**：16k*8→128k\*8

字扩展的128k地址线（17）多于16k（14）.多出的三根数据线作为片选译码器输入信号。

![](https://s3.bmp.ovh/imgs/2022/04/12/844102cad55605f1.png)

A14 A15 A16 作为片选信号

For第0片，地址：00000H—03FFFH（==000==0000··00—==000==1111···11）依次类推。



<img src="https://s3.bmp.ovh/imgs/2022/04/12/e70abcf1f8ba6a43.png" style="zoom:80%;" />

需要进行字位扩展。00 01 10 11（max）

1. 1B1F地址所在的芯片是哪一块芯片？

   ==11==  0110  0011  111  **or**  ==1==  1011  0001  1111

2.  该块芯片是==11==，所以最大是==11==  1111  1111  111，即1  1111  1111  1111（1FFF）H。



<img src="https://s3.bmp.ovh/imgs/2022/04/12/d3da9bb2f31a6e83.png" style="zoom:80%;" />

>==10== 00  0000  0000  0000  后面的一共十四位。
>
>==10== 11  1111  1111  1111



<img src="https://s3.bmp.ovh/imgs/2022/04/12/c08763508ceb09ac.png" style="zoom:80%;" />



### 相连存储器

> 如何快速判断CPU要访问的内容是否在Cache中？
>
> --使用主存的部分地址来查找。

**判断的思路**：根据不同规则抽取主存地址的部分内容作为查找的判据。

**相连存储器**：通过硬件并发查找。（因为这里的速度都很快，像数据结构中的查找算法太！慢！了！）

![](https://s3.bmp.ovh/imgs/2022/04/12/d5f7f626b0745a13.png)



<img src="https://s3.bmp.ovh/imgs/2022/04/13/e055cb2f4164f10a.png"  />

相连存储器中存放的是

我想之所以是并行比较是因为：

> 相联存储器(CAM)是一种特殊的存储器，是一种基于数据内容进行访问的存储设备，特点是每个存储单元都必须有一个处理单元。
>
> 当对其写入数据时，CAM能够自动选择一个未用的空单元进行存储；
>
> 当要读出数据时，不是给出其存储单元的地址，而是直接给出该数据或该数据的一部分内容，CAM对所有的存储单元中的数据同时进行比较，并标记符合条件的所有数据以供读取。
>
> 由于比较是同时、并行进行的，所以这种基于数据内容进行读/写的机制，其速度比基于地址进行读/写的方式要快许多。



### 多体交叉存储器

==在不提供存储器速率，不扩展数据总线位数的前提下==，通过存储芯片的交叉组织，提高CPU单位时间内访问的数据量，从而缓解快速CPU与慢速的主存之间的速度差异。

![](https://s3.bmp.ovh/imgs/2022/04/12/95d469bbc491080d.png)

对于高位（顺序）存储时的内存地址=模块+字；所以M0里是00 000、00 001、00 010···；

但是低位是内存地址=字+模块；存到数据组织里的时候是 000 00、001 00、010 00、 011 00····这样。

![](https://s3.bmp.ovh/imgs/2022/04/12/414a00c6f13ee34c.png)

![](https://s3.bmp.ovh/imgs/2022/04/12/1f9edd94e6651c70.png)

<img src="https://s3.bmp.ovh/imgs/2022/04/13/e1e341410f3acd4e.png" style="zoom: 80%;" />

> 这个是32*4=128.而不是拿64k来乘。







## 高速缓存存储器

### Cache的基本原理

在==任何存在速度差异的地方==均配有Cache。但我们主要讨论的是CPU和主存之间的Cache。

Cache的功能：缓解快速CPU和慢速主存之间的速度差异。

Cache的理论基础：局部性原理。

==如果命中==：

> 如何判断数据是否在Cahce中？
>
> Cache中的数据是否有效？（外设可能会更改数据、DMA修改主存）





## 虚拟存储器





## 外部存储器





